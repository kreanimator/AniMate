# AniMate

A Blender plugin for animating humanoid rigs using motion capture data from MediaPipe.

## Features

- Real-time motion capture using MediaPipe
- Support for pose, face, and hand tracking
- Configurable bone mappings
- Test rigs for development and testing
- Modular and extensible architecture

## Project Status

ðŸš§ **Under Development** ðŸš§

The project is currently in active development. Core functionality is implemented but may have bugs or missing features.

## Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/AniMate.git
cd AniMate
```

2. Install Python dependencies:
```bash
pip install -r requirements.txt
```

3. Create a ZIP file for the Blender addon:
```bash
zip -r animate_addon.zip animate_addon
```

4. Install the Blender addon:
   - Open Blender
   - Go to Edit > Preferences > Add-ons
   - Click "Install" and select the `animate_addon.zip` file you just created
   - Enable the addon by checking the box next to "Animation: AniMate"

## Project Structure

```
AniMate/
â”œâ”€â”€ animate_addon/         # Blender addon files
â”‚   â””â”€â”€ __init__.py       # Addon initialization and UI
â”œâ”€â”€ data/                  # Data and configuration files
â”‚   â”œâ”€â”€ bone_mappings.py   # MediaPipe to Blender bone mappings
â”‚   â”œâ”€â”€ landmark_structure.py # MediaPipe landmark definitions
â”‚   â””â”€â”€ test_rigs.py       # Test rig configurations
â”œâ”€â”€ examples/              # Example scripts
â”‚   â””â”€â”€ live_capture.py    # Live motion capture example
â”œâ”€â”€ rig/                   # Blender rig functionality
â”‚   â”œâ”€â”€ blender_mapper.py  # Blender-specific rig mapping
â”‚   â””â”€â”€ retargeting.py     # Retargeting functionality
â”œâ”€â”€ tests/                 # Test scripts
â”‚   â”œâ”€â”€ test_detection.py  # MediaPipe detection tests
â”‚   â””â”€â”€ test_rig.py        # Rig functionality tests
â”œâ”€â”€ utils/                 # Utility functions
â”‚   â””â”€â”€ detection.py       # MediaPipe detection module
â””â”€â”€ README.md             # This file
```

## Usage

### In Blender

1. Open Blender and load your humanoid rig
2. In the 3D Viewport, open the sidebar (N key)
3. Go to the "AniMate" tab
4. Select your armature in the "Target Armature" field
5. Configure detection settings (pose, face, hands)
6. Click "Start Capture" to begin motion capture

### Testing Detection

To test the MediaPipe detection functionality without Blender:

```bash
python tests/test_detection.py
```

Controls:
- 'p' - Toggle pose detection
- 'f' - Toggle face detection
- 'h' - Toggle hand detection
- 'ESC' - Exit

## Development

### Adding New Features

1. Detection:
   - Add new detection types in `utils/detection.py`
   - Update bone mappings in `data/bone_mappings.py`

2. Rig Support:
   - Add new rig configurations in `data/test_rigs.py`
   - Implement rig-specific mapping in `rig/blender_mapper.py`

3. Addon UI:
   - Modify `animate_addon/__init__.py` to add new UI elements
   - Add new operators and properties as needed

### Testing

1. Run detection tests:
```bash
python tests/test_detection.py
```

2. Run rig tests:
```bash
python tests/test_rig.py
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- MediaPipe for the motion capture technology
- Blender for the 3D animation platform
